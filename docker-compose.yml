services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    environment:
      - node.name=elasticsearch
      - cluster.name=docker-cluster
      - discovery.type=single-node        # 단일 노드 모드로 실행 (개발/테스트용)
      - bootstrap.memory_lock=true        # 메모리 스와핑 방지를 위한 설정
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"     # JVM 힙 메모리 최소/최대 1GB로 설정
      - xpack.security.enabled=false      # X-Pack 보안 기능 비활성화 (개발용)
      - xpack.security.transport.ssl.enabled=false  # SSL 전송 암호화 비활성화
    ulimits:
      memlock: # 메모리 잠금 제한 설정 (성능 향상을 위해)
        soft: -1  # 소프트 제한 무제한
        hard: -1  # 하드 제한 무제한
    volumes:
      # Elasticsearch 데이터를 영구 볼륨에 저장
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"  # HTTP API 포트 (REST API 접근용)
      - "9300:9300"  # 노드 간 통신 포트 (클러스터 통신용)
    networks:
      - elk  # elk 네트워크에 연결
    healthcheck:
      test: [ "CMD-SHELL", "curl --silent --fail localhost:9200/_cluster/health || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3

  # Logstash 서비스 - 로그 수집, 변환, 전송 파이프라인
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0  # Logstash 8.11.0 이미지 사용
    container_name: logstash  # 컨테이너 이름 지정
    environment:
      - "LS_JAVA_OPTS=-Xmx512m -Xms512m"  # Logstash JVM 메모리 설정 (512MB)
    volumes:
      # Logstash 설정 파일들을 컨테이너에 마운트 (읽기 전용)
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro  # 파이프라인 설정 파일들
      - ./logs:/usr/share/logstash/logs:ro # 로그 파일
    ports:
      - "5044:5044"    # Beats 입력 포트 (Filebeat, Metricbeat 등)
      - "5050:5050/tcp"  # TCP 로그 입력 포트
      - "5050:5050/udp"  # UDP 로그 입력 포트
      - "9600:9600"    # Logstash API 포트 (모니터링용)
    networks:
      - elk  # elk 네트워크에 연결
    depends_on:
      - elasticsearch  # Elasticsearch가 먼저 시작된 후 Logstash 시작
    # 헬스체크 추가
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9600" ]
      interval: 30s
      timeout: 10s
      retries: 5
    # Elasticsearch가 완전히 준비될 때까지 대기
    restart: unless-stopped

  # Kibana 서비스 - 데이터 시각화 및 대시보드 웹 인터페이스
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0  # Kibana 8.11.0 이미지 사용
    container_name: kibana  # 컨테이너 이름 지정
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200  # Elasticsearch 연결 주소
      - xpack.security.enabled=false
    ports:
      - "5601:5601"
    networks:
      - elk
    depends_on:
      - elasticsearch

  # Filebeat - 시스템 로그 수집
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: filebeat
    user: root
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro # Filebeat 설정파일
      - ./logs:/usr/share/filebeat/logs # Spring Boot 로그 파일 (애플리케이션과 공유)
    depends_on:
      - elasticsearch
      - logstash
    networks:
      - elk

  # S3 백업 전용 컨테이너 (스크립트 기반 - 안정적)
  backup:
    image: alpine:latest
    container_name: backup
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - S3_BUCKET=${S3_LOG_BUCKET}
      - S3_PREFIX=${S3_LOG_PREFIX}
    volumes:
      - ./logs:/logs
    restart: unless-stopped
    command: |
      sh -c '
       apk add --no-cache aws-cli dcron
      
        # 한 번에 모든 크론 작업 설정
        # 30분마다 .gz 파일 체크 후 s3업로드(테스트)
        # 새벽 2시마다 7일이상 지난 파일 정리
        # 디스크 사용량 80% 이상시 긴급 정리 (매시간 체크)
        echo "*/30 * * * * find /logs -name \"*.gz\" -exec aws s3 cp {} s3://'"$$S3_BUCKET"'/'"$$S3_PREFIX"'/\$(date +%Y/%m/%d)/ \; -delete
        0 2 * * * find /logs -name \"*.log\" -mtime +7 -delete; find /logs -type d -empty -delete  
        0 * * * * [ \$(df /logs | awk \"NR==2 {print \\\$5}\" | sed \"s/%//\") -gt 80 ] && find /logs -name \"*.log\" -mtime +3 -delete" | crontab -
      
        echo "All cron jobs configured:"
        crontab -l
      
        crond && tail -f /dev/null
      '
    networks:
      - elk

  kafka:
    image: confluentinc/cp-kafka:7.6.0
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"                    # 외부 접속용 포트 (Spring Boot에서 사용)
      - "9101:9101"                    # JMX 모니터링 포트
    networks:
      - elk
    volumes:
      - kafka_data:/var/lib/kafka/data
    environment:
      # 노드 정보 설정
      KAFKA_NODE_ID: 1                 # 노드 고유 ID (클러스터 내 유일해야 함)
      KAFKA_PROCESS_ROLES: 'broker,controller'  # 이 노드가 브로커와 컨트롤러 역할 둘 다 수행
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'     # 클러스터 고유 ID (변경 가능)
      # 리스터 설정
      # 각 리스너의 보안 프로토콜 정의 (개발용이라 모두 PLAINTEXT)
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      # - PLAINTEXT: 컨테이너 내부 통신용 (29092)
      # - CONTROLLER: KRaft 컨트롤러 통신용 (29093)
      # - PLAINTEXT_HOST: 외부 접속용 (9092)
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092'
      # 클라이언트에게 알려줄 주소들 -> 컨테이너 내부는 29092, 외부에서는 localhost:9092로 접속
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'      # 브로커 간 통신에 사용할 리스너
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'      # 컨트롤러 통신에 사용할 리스너
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093'    # 컨트롤러 투표 참여자 (노드1이 29093 포트)
      # === 토픽 및 복제 설정 ===
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1          # __consumer_offsets 토픽 복제 팩터 (단일 브로커라 1)
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'            # 토픽 자동 생성 허용
      # === 성능 및 안정성 설정 ===
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0          # 컨슈머 그룹 리밸런싱 지연시간 (개발용 0)
      KAFKA_LOG_DIRS: '/var/lib/kafka/data'          # 로그 파일 저장 경로
    healthcheck:
      test: [ "CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # Kafka UI (선택사항 - 관리 편의성을 위해)
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    networks:
      - elk
    ports:
      - "28080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: "docker-local"
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: "kafka:29092"
    depends_on:
      kafka:
        condition: service_healthy

volumes:
  elasticsearch_data: # docker 볼륨 이름
    driver: local # docker가 기본 방식으로 로컬 디스크에 데이터를 저장
  kafka_data:
    driver: local
networks:
  elk: # ELK가 서로 네트워크 상에서 통신할 수 있게 도와줌
    driver: bridge # 기본 브리지 네트워크 방식 사용